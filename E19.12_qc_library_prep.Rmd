---
title: "E19.12_qc_library_prep"
author: "Chandler Sutherland"
date: "2025-05-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ggplot2)
require(tidyverse)
library(openxlsx)
library(patchwork)
```

Copyright Â© Chandler Sutherland Email: [chandlersutherland\@berkeley.edu](mailto:chandlersutherland@berkeley.edu){.email}

Purpose: produce a custom QC report for the E19.12 experiment. 

## put back in yield info 

Relative to the amount of DNA input into the first part of the pipeline, only recover 0.4-1%. However, this is plenty of fmol to work with before PCR amplification. 


Look at the fragment distribution: 

Col-0 gDNA 7	CS26
Col-0 gDNA 9 	CS27
Col-0 gDNA 10 	CS28
msh2 gDNA 2	CS29
msh2 gDNA 4	CS30
msh2 gDNA 7	CS31
uni1d gDNA 1	CS32
uni1d gDNA 2	CS33
uni1d gDNA 3	CS34

```{r}
#load data 
frag_traces_1 <- read_csv("C:\\Users\\chand\\Box Sync\\Krasileva_Lab\\Research\\chandler\\Krasileva Lab\\E19\\fragment analysis\\20250514\\2025 05 13 17H 59M Electropherogram.csv") %>%
  pivot_longer(cols=`C1: CS 26`:`A9: CS 34`, names_to='sample', values_to='Intensity') %>% 
  separate('sample', c(NA, 'sample', 'number'))  %>% 
  rename(size = `Size (bp)`) %>% 
  mutate(sample_number=paste(sample, number, sep='_'))%>%
  mutate(plant_id=case_when(sample_number=='CS_26' ~ 'Col0_7', 
                            sample_number=='CS_27' ~ 'Col0_9',
                            sample_number=='CS_28' ~ 'Col0_10', 
                            sample_number=='CS_29' ~ 'msh2_2', 
                            sample_number=='CS_30' ~ 'msh2_4', 
                            sample_number=='CS_31' ~ 'msh2_7', 
                            sample_number=='CS_32' ~ 'uni1d_1', 
                            sample_number=='CS_33' ~ 'uni1d_2', 
                            sample_number=='CS_34' ~ 'uni1d_3'
                            ))%>%
  mutate(sample=case_when(sample_number=='CS_26' ~ 'sample_1', 
                            sample_number=='CS_27' ~ 'sample_2',
                            sample_number=='CS_28' ~ 'sample_3', 
                            sample_number=='CS_29' ~ 'sample_4', 
                            sample_number=='CS_30' ~ 'sample_5', 
                            sample_number=='CS_31' ~ 'sample_6', 
                            sample_number=='CS_32' ~ 'sample_7', 
                            sample_number=='CS_33' ~ 'sample_8', 
                            sample_number=='CS_34' ~ 'sample_9'
                            )) %>%
  separate(plant_id, sep='_', into=c('genotype', NA), remove=FALSE)

frag_traces_1$plant_id <- as.factor(frag_traces_1$plant_id)

pre_pcr <- ggplot() +
  geom_line(data=frag_traces_1, aes(x=size, y= Intensity, color=plant_id))+
  scale_x_log10(limits=c(10,NA), breaks=c(10, 100, 200, 300, 400,500, 600, 700, 800, 1000, 1500,3000,6000))+
  ylim(0, 2000)+
  theme_classic()+
  geom_vline(xintercept=200, linetype=2, color='grey')+
  geom_vline(xintercept=1000, linetype=2, color='grey')+
  facet_wrap(~genotype)

pre_pcr
```


Fragment Sizes:
```{r}
frag_traces_1 %>% filter(size > 100 & size <=800)
```


## Dilution and re-qPCR 

Measured pre-PCR libraries on 05/14 and 05/15 with a new set of standards. Used the positive control and previous standards to calibrate new standards (14.25pM standard 1). Diluted to ideally 0.01 nM on 05/19 and 05/20, re-qPCR checked, then back calculated with my dilution factor what the estimate of the library was. 

How much noise am I getting? 

```{r}
pre_pcr_1 <- read.xlsx("C:\\Users\\chand\\Box Sync\\Krasileva_Lab\\Research\\chandler\\Krasileva Lab\\E19\\Library qPCR\\E19.12 pre-pcr qpcr.xlsx", sheet='both_replicates')

pre_pcr_1$date <- factor(pre_pcr_1$date, levels=c('20250514', '20250515', '20250519', '20250520', '20250521', 'average'))
ggplot(pre_pcr_1)+
  #geom_boxplot(aes(x=library, y=estimate))+
  geom_point(aes(x=library, y=estimate, color=date))+
  theme_classic()+
  xlab('')+
  ylab('working concentration (nM)')

my_sum <- pre_pcr_1 %>%
  group_by(library, date) %>%
  summarise( 
    n=n(),
    mean=mean(estimate, na.rm=T),
    sd=sd(estimate, na.rm= T)
  ) %>%
  mutate( se=sd/sqrt(n))  %>%
  mutate( ic=se * qt((1-0.05)/2 + .5, n-1))

ggplot() +
  geom_bar(my_sum, mapping=aes(x=library, y=mean, fill=date), stat='identity', alpha=0.5, position='dodge') +
#  geom_errorbar(my_sum, mapping=aes(x=library, ymin=mean-ic, ymax=mean+ic), width=0.4, alpha=0.9, position='dodge') +
  geom_point(pre_pcr_1, mapping=aes(x=library, y=estimate, color=date, shape=replicate), position=position_dodge(width=1))+
  ggtitle("Library Estimate")+
  ylab('nM')+
  theme_classic()

controls <- pre_pcr_1 %>% filter(str_detect(library, "^positive"))
```

However, serial dilutions are not true replicates. 20250519 overestimates, 20250514 underestimates, and 20250515 appears somewhat in the middle. 

```{r}
pre_pcr_1_avg <- read.xlsx("C:\\Users\\chand\\Box Sync\\Krasileva_Lab\\Research\\chandler\\Krasileva Lab\\E19\\Library qPCR\\E19.12 pre-pcr qpcr.xlsx", sheet='average')

pre_pcr_1_avg$date <- factor(pre_pcr_1_avg$date, levels=c('20250514', '20250515', '20250519', '20250520', '20250521', 'average'))
ggplot(pre_pcr_1_avg)+
  geom_boxplot(aes(x=library, y=estimate))+
  geom_point(aes(x=library, y=estimate, color=date))+
  theme_classic()+
  xlab('')+
  ylab('working concentration (nM)')

my_sum <- pre_pcr_1_avg %>%
  group_by(library) %>%
  summarise( 
    n=n(),
    mean=mean(estimate, na.rm=T),
    sd=sd(estimate, na.rm= T)
  ) %>%
  mutate( se=sd/sqrt(n))  %>%
  mutate( ic=se * qt((1-0.05)/2 + .5, n-1))

ggplot() +
  geom_bar(my_sum, mapping=aes(x=library, y=mean), stat="identity", alpha=0.5) +
  geom_errorbar(my_sum, mapping=aes(x=library, ymin=mean-ic, ymax=mean+ic), width=0.4, alpha=0.9) +
  geom_point(pre_pcr_1_avg, mapping=aes(x=library, y=estimate, color=date))+
  ggtitle("Average library estimate 95% confidence interval")+
  theme_classic()

pre_pcr_1_avg %>% filter(library %in% c('library 7', 'library 8', 'library 9')) %>% filter(date != '20250521') %>% group_by(library) %>% summarize(mean=mean(estimate))
```

remove 20250514, can't trust it (positive control looked crazy). Take average of 20250519 and 20250515, re-dilute, re-qPCR 
```{r}
working_conc <- pre_pcr_1_avg %>% 
  filter(date != '20250514') %>% 
  filter(!(date == '20250515' & library %in% c('library 1', 'library 2', 'library 3', 'library 4', 'library 5', 'library 6'))) %>%
  group_by(library) %>% summarize(mean=mean(estimate))

ggplot() +
  geom_bar(my_sum, mapping=aes(x=library, y=mean, fill=date), stat='identity', alpha=0.5, position='dodge') +
  geom_boxplot(working_conc, mapping=aes(x=library, y=mean))+
  geom_point(pre_pcr_1_avg, mapping=aes(x=library, y=estimate, color=date, shape=replicate), position=position_dodge(width=1))+
  ggtitle("Library Estimate")+
  ylab('nM')+
  theme_classic()
```


Actual dilution results: 
```{r}
dilution_1 <- read.xlsx("C:\\Users\\chand\\Box Sync\\Krasileva_Lab\\Research\\chandler\\Krasileva Lab\\E19\\Library qPCR\\E19.12 pre-pcr qpcr.xlsx", sheet='dilution')

dilution_1$date <- factor(dilution_1$date, levels=c('20250519', '20250520', '20250521'))
nM <- ggplot(dilution_1)+
  geom_hline(yintercept=0.01, color='red')+
  geom_point(aes(x=library, y=estimate, color=date))+
  theme_classic()+
  ylim(0, 0.05)+
  xlab('')+
  ylab('working concentration (nM)')

fmol <- ggplot(dilution_1)+
  geom_hline(yintercept=0.2, color='red')+
  geom_hline(yintercept=0.18, color='red', linetype=2)+
  geom_hline(yintercept=0.22, color='red', linetype=2)+
  geom_point(aes(x=library, y=fmol, color=date))+
  ylim(0, 0.5)+
  theme_classic()+
  xlab('')+
  ylab('fmol input to PCR in 20ul')

nM + fmol + plot_layout(guides='collect')
```

```{r}
pre_pcr_1 %>% filter(date %in% c('20250515', '20250514')) %>% ggplot(aes(x=library, y=estimate, color=date))+
  geom_point()+
  theme_classic()

#load everything and calculate ideal based only on the 20250514 and 15 estimates of library size. 
dilution_trials_1 <- pre_pcr_1 %>% filter(date %in% c('20250515', '20250514')) %>% 
  group_by(library) %>% 
  summarize(estimate=mean(estimate, na.rm=T)) %>%
  mutate(vol_0519 = c(8.20, 3.88, 3.38, 2.96, 4.63, 4.10, 2.55, 1.98, 4.72, NA, NA)) %>%
  mutate(ideal_0519 = estimate*vol_0519/50) %>%
  mutate(est_0519 = c(0.023, 0.023, 0.025, 0.019, 0.028, 0.023, 0.009, 0.007, 0.015, NA, NA)) %>%
  mutate(vol_0520 = c(6.43, 2.96, 2.45, 2.45, 3.21, 3.17, 3.38, 2.94, 5.01, NA, NA))%>% 
  mutate(ideal_0520 = estimate*vol_0520/50) %>%
  mutate(est_0520 = c(0.013, 0.014, 0.012, 0.011, 0.012, 0.015, 0.011, 0.013, 0.011, NA, NA)) %>%
  mutate(vol_0521 = c(12.37, 5.13, 3.71, 5.02, 5.79, 4.82, 6.66, 5.37, 11.02, NA, NA))%>%
  mutate(ideal_0521 = estimate*vol_0521/100) %>%
  mutate(est_0521 = c(0.016, 0.014, 0.015, 0.019, 0.019, 0.016, 0.018, 0.016, 0.017, NA, NA))

clean_dil_trial <- dilution_trials_1 %>% 
  subset(select=c(library, ideal_0519, ideal_0520, ideal_0521, est_0519, est_0520, est_0521)) %>%
  filter(str_detect(library, '^library')) %>%
  pivot_longer(cols=!library, names_to='date', values_to='value') %>%
  separate(date, into=c('type', 'date'), sep='_') %>%
  mutate(date=paste0('2025',date)) %>%
  pivot_wider(names_from=type, values_from=value)

clean_dil_trial %>% group_by(date) %>% summarize(avg_conc=mean(est))

ggplot(clean_dil_trial)+
  geom_point(aes(x=ideal, y=est, color=date))+
  geom_abline(slope=1, intercept=0)+
  geom_hline(yintercept = 0.01911111, color='#F8766D')+
  geom_hline(yintercept=0.01244444, color='#00BA38')+
  geom_hline(yintercept=0.01666667, color='#619CFF')+
  #scale_x_log10()+
 # scale_y_log10()+
   ylim(0, 0.03)+
  xlim(0, 0.015)+
  theme_classic()
```
Ok, a lot more noise than my other graphs, so the estimates of the libraries from 20250514 and 20250515 are not super accurate. My best dilution series was 20250520, in that it was most consistently close to 0.010, but I'm like factoring in an underestimate. It's not actually that much closer to the ideal v estimate line. 


```{r}
dilution_1 %>% mutate(ideal_nm = 0.01) %>%
  ggplot()+
  geom_point(aes(x=ideal_nm, y=estimate, color=date))+
  ylim(0, 0.022)+
  theme_classic()
```


# Retry!
Did everything on the same day, with 6 independent dilutions per library. It's time to get tennis elbow. 

## Pre-pcr quantification 
```{r}
pre_pcr_2 <- read.xlsx("C:\\Users\\chand\\Box Sync\\Krasileva_Lab\\Research\\chandler\\Krasileva Lab\\E19\\Library qPCR\\20250527.xlsx", sheet='Final Result', startRow=2, cols=c(1:4)) %>%
  rename('library' = 'X1', 'replicate' = 'X2', 'estimate' = 'nM')
```

First, how well did this run go? Two metrics: positive controls and benchmarks, dilutions of previous libraries. 
```{r}
pos_control <- pre_pcr_2 %>% 
  filter(str_detect(library, '^positive')) %>% 
  mutate(date='20250527') %>% 
  subset(select=-fragment.size)

all_controls <- rbind(pos_control, controls) %>% 
  mutate(replicate=str_replace(replicate, 'dilution', 'rep')) %>%
  mutate(library=str_trim(str_replace(library, 'positive control ', 'positive_'
                             )))

ggplot(all_controls)+
  geom_boxplot(aes(x=library, y=estimate))+
  geom_point(aes(x=library, y=estimate, color=date, shape=replicate), position='jitter')+
  scale_color_manual(values=c("20250527" = 'purple', "20250521"='grey', "20250514" = 'grey', "20250515" = 'grey', "20250519" = 'grey', "average" = 'red',  "20250520" = 'grey'))+
  theme_classic()
```

Within the realm of possibility. rep1 of positive old is a little low. 

```{r}
bench <- pre_pcr_2 %>% filter(str_detect(library, '^benchmark')) %>% mutate(date='20250527') %>% subset(select=c(library, estimate, date))

ideal <- data.frame(library = c('benchmark 1', 'benchmark 2', 'benchmark 3', 'benchmark 4', 'benchmark 5', 'benchmark 6'),
           estimate = c(0.1, 0.04, 0.02, 0.01, 0.005, 0.0095)) %>%
  mutate(date='ideal')

bench_comp <- data.frame(library = c('benchmark 1', 'benchmark 2', 'benchmark 3', 'benchmark 4', 'benchmark 5', 'benchmark 6'),
           estimate = c(0.10236388, 0.056525321, 0.035209386, 0.012646095, 0.00784119, NA)) %>%
  mutate(date='20250121') %>%
  rbind(bench) %>%
  rbind(ideal)

ggplot(bench_comp)+
  geom_point(aes(x=library, y=estimate, color=date))+
  ylab('nM estimate')+
  theme_classic()+
ggplot(bench_comp)+
  geom_point(aes(x=library, y=estimate, color=date))+
  scale_y_log10()+
  ylab('log10(nM estimate)')+
  theme_classic()+
  plot_layout(guides='collect')
```
Pretty close. Except as seen previously, have a higher time with larger estimates. But otherwise ok. 

```{r}
lib_only <- pre_pcr_2 %>% filter(str_detect(library, '^Library'))

ggplot(lib_only)+
  geom_boxplot(aes(x=library, y=estimate))+
  geom_point(aes(x=library, y=estimate, color=replicate))+
  theme_classic()+
  xlab('')+
  ylab('working concentration (nM)')

noise_summary <- lib_only %>% group_by(library) %>%
  summarise( 
    n=n(),
    mean=mean(estimate, na.rm=T),
    sd=sd(estimate, na.rm= T)
  ) %>%
  mutate( se=sd/sqrt(n))  %>%
  mutate( ic=se * qt((1-0.05)/2 + .5, n-1)) %>%
  mutate(cv = sd/mean*100)

ggplot() +
  geom_bar(noise_summary, mapping=aes(x=library, y=mean), stat='identity', alpha=0.5) +
  geom_errorbar(noise_summary, mapping=aes(x=library, ymin=mean-ic, ymax=mean+ic), width=0.4, alpha=0.9, position='dodge') +
  geom_point(lib_only, mapping=aes(x=library, y=estimate))+
  ggtitle("Library Estimate (confidence intervals)")+
  ylab('nM')+
  theme_classic()

ggplot() +
  geom_bar(noise_summary, mapping=aes(x=library, y=mean), stat='identity', alpha=0.5) +
  geom_errorbar(noise_summary, mapping=aes(x=library, ymin=mean-sd, ymax=mean+sd), width=0.4, alpha=0.9, position='dodge') +
  geom_point(lib_only, mapping=aes(x=library, y=estimate))+
  ggtitle("Library Estimate (sd)")+
  ylab('nM')+
  theme_classic()

noise_summary
```
Pretty tight, some issue with dilution 4 library 3. Library 9 is a lot less than the others. Coefficient of variation between different measurements of the same library between 10-22% (except for Library 3). This is acceptable. 


```{r}
#ng/ul measurement
noise_summary %>% subset(select=c(library, mean)) %>%
  mutate(ng_ul=mean/10^6*660*517) %>% pull(ng_ul)
```

## Dilution and re-measurement 

In an attempt to prevent super crazy dilutions over and over, did three dilutions for each library. Tube 1 should be 0.0075, tube 2 0.01, tube 3 0.00125 
```{r}
dil_2 <- read.xlsx("C:\\Users\\chand\\Box Sync\\Krasileva_Lab\\Research\\chandler\\Krasileva Lab\\E19\\Library qPCR\\20250527_2.xlsx", sheet='Final Result', startRow=2, cols=c(1:5)) %>%
  rename('library' = 'X1', 'replicate' = 'X3', 'estimate' = 'nM')

dil_2
```

Once again, check controls 
```{r}
pos_control <- dil_2 %>% filter(str_detect(library, '^positive')) %>% mutate(date='20250527_2') %>% subset(select=-c(fragment.size, Tube))
all_controls <- rbind(pos_control, all_controls) %>% 
  mutate(replicate=str_replace(replicate, 'dilution', 'rep')) %>%
  mutate(library=str_trim(str_replace(library, 'positive control ', 'positive_'
                             )))

ggplot(all_controls)+
  geom_boxplot(aes(x=library, y=estimate))+
  geom_point(aes(x=library, y=estimate, color=date, shape=replicate), position='jitter')+
  scale_color_manual(values=c("20250527_2" = 'purple', "20250527" = 'grey', "20250521"='grey', "20250514" = 'grey', "20250515" = 'grey', "20250519" = 'grey', "average" = 'red',  "20250520" = 'grey'))+
  #scale_y_log10()+
  theme_classic()
```
Acceptable I guess 

0.1
0.04
0.02
0.01
0.005
0.0095

Is there a significant relationship between time and factor difference between ideal and estimate? Caveat: 20250527 replicates were done on the same dilutions, so I should probably average them 
```{r}
bench_2 <- dil_2 %>% filter(str_detect(library, '^benchmark')) %>% 
  mutate(date='20250527_2') %>% 
  subset(select=c(library, estimate, date))

bench_comp_2 <- bench_comp %>% rbind(bench_2)

ggplot(bench_comp_2)+
  geom_point(aes(x=library, y=estimate, color=date))+
  scale_y_log10()+
  theme_classic()

versus <- bench_comp_2 %>% 
  pivot_wider(names_from=date, values_from=estimate) %>% 
  pivot_longer(cols = starts_with('2025'), names_to='date', values_to = 'estimate') %>%
  mutate(estimate=case_when(date=='20250121' & library=='benchmark 6' ~ NA, 
                            .default=estimate)) %>%
  mutate(date=case_when(date=='20250527_2' ~ '20250527', 
                        .default=date))%>%
  group_by(date, library, ideal)%>%
  summarize(estimate=mean(estimate, na.rm=T))

ggplot(versus)+
  geom_point(aes(x=ideal, y=estimate, color=date))+
  geom_abline(slope=1, intercept=0)+
  ylim(0, 0.18)+
  xlim(0, 0.18)+
  scale_x_log10()+
  scale_y_log10()+
  theme_classic()

factor_dif <- versus %>% mutate(dif=estimate-ideal) %>% mutate(factor=estimate/ideal) 

factor_dif %>%
  ggplot(aes(x=date, y=factor))+
  geom_hline(yintercept=1)+
  ylab('factor difference between ideal and actual dilution nM')+
  ylim(0, 2.5)+
  geom_boxplot()+
  geom_point(aes(color=library))+
  theme_classic()

factor_dif %>% group_by(date) %>% summarize(mean(factor, na.rm=T))

factor_dif
x <- factor_dif %>% filter(date=='20250121') %>% pull(factor)
y <- factor_dif %>% filter(date=='20250527') %>% pull(factor)

t.test(x, y)
```

There was always overestimation of libraries, and my new standards do not increase this significantly (1.4x to 1.6x)

For sure. More accurate benchmark 1, less benchmark 2, otherwise pretty close. The dilution on this was crazy so handwavey anyway. Not real tech reps bc from the same dilution. 

In an attempt to prevent super crazy dilutions over and over, did three dilutions for each library. Tube 1 should be 0.0075, tube 2 0.01, tube 3 0.00125 
```{r}
dilution <- dil_2 %>% filter(str_detect(library, '^Library'))

nM <- ggplot(dilution)+
  geom_hline(yintercept=0.01, color='#00BA38')+
  geom_hline(yintercept=0.0075, color='#F8766D')+
  geom_hline(yintercept=0.0125, color='#619CFF')+
  geom_boxplot(aes(x=library, y=estimate, color=Tube))+
  theme_classic()+
  ylim(0, 0.03)+
  xlab('')+
  ylab('working concentration (nM)')

summary <- dilution %>% group_by(library, Tube) %>% summarize(estimate=mean(estimate, na.rm=T)) %>% mutate(fmol=estimate*20)

fmol <- ggplot(summary)+
  geom_hline(yintercept=0.2, color='red')+
  geom_hline(yintercept=0.18, color='red', linetype=2)+ #lower bound conservative estimate
  geom_hline(yintercept=0.22, color='red', linetype=2)+ #upper bound empirical estimate 
  geom_point(aes(x=library, y=fmol, color=Tube))+
  ylim(0, 0.5)+
  theme_classic()+
  xlab('')+
  ylab('fmol input to PCR in 20ul')

nM + fmol + plot_layout(guides='collect')
```

```{r}
dilution %>% 
  group_by(Tube) %>% 
  summarize(mean=mean(estimate, na.rm=T)) %>% 
  mutate(ideal=c(0.0075, 0.01, 0.0125)) %>% 
  mutate(dif=mean-ideal) %>%
  mutate(factor=mean/ideal)%>%
  mutate(fmol=mean*20)

dilution %>% filter(Tube=='tube 1') %>% group_by(library) %>% summarize(nM=mean(estimate))
```

Proceed with tube 1. 

The issue isn't inaccurate pipetting, it seems to be that no matter what there's an issue where I make the wrong estimate of the first library, leading to a inflated after dilution. This is probably because my qPCR based measurement isn't accurate, as in the standard is more accurate at certain concentrations. In my first library, I messed up my initial math and that likely compensated for this. I don't really know how to proceed with this. I wonder if that's why my standards always have messed up delta Ct values at the end. But everything I measure is in the same ballpark anyway. 

```{r}
versus

more_versus <- dilution %>% 
  group_by(library, Tube) %>% 
  summarize(estimate=mean(estimate, na.rm=T)) %>% 
  mutate(ideal = case_when(Tube == 'tube 1' ~ 0.0075, 
                                      Tube == 'tube 2' ~ 0.01, 
                                      Tube == 'tube 3' ~ 0.0125))

ggplot(more_versus)+
  geom_point(aes(x=ideal, y=estimate, color=Tube))+
  geom_abline(slope=1, intercept=0)+
  ylim(0, 0.02)+
  xlim(0, 0.02)+
  theme_classic()

bench_and_dil <- more_versus %>% 
  mutate(date='20250527_2') %>% 
  rbind(versus %>% mutate(Tube=library)) 

bench_and_dil %>%
  ggplot()+
  geom_point(aes(x=ideal, y=estimate, color=Tube))+
  geom_abline(slope=1, intercept=0)+
  geom_hline(yintercept=0.01, color='red')+
  geom_hline(yintercept=0.012, color='red', linetype=2)+
  #ylim(0, 0.02)+
  #xlim(0, 0.02)+
  scale_x_log10(guide='axis_logticks')+
  scale_y_log10()+
  theme_classic()

bench_and_dil %>%
  ggplot()+
  geom_point(aes(x=library, y=estimate, color=Tube, shape=date))+
  theme_classic()+
  ylim(0, 0.02)

dil_2 %>% mutate(date='20250527')

```

# Library amplification efficiency 
WW suggested that it was a difference in primer efficiency between my standard curve and sample. Test with benchmark 20250527 and original results. 

```{r}
#start with january 2021 measurement 
raw_1 <- read.xlsx("C:\\Users\\chand\\Box Sync\\Krasileva_Lab\\Research\\chandler\\Krasileva Lab\\E19\\Library qPCR\\20250121 dilution curve quant 1(SYBR) recalc 20250529.xlsx", sheet='Concentration Analysis', startRow=1, fillMergedCells = TRUE)  %>%
  mutate(Ct=as.double(Ct))

benchmark_raw_1 <- raw_1 %>% 
  filter(str_detect(sample, '^Dilution')) %>% 
  subset(select=c(sample, Average.Ct, dilution.factor)) %>% 
  unique() %>% 
  separate(sample, into=c(NA, 'dilution', 'replicate'), sep=' ') %>%
  mutate(benchmark = case_when(dilution == '2' ~ '1', 
                               dilution == '3' ~ '2', 
                               dilution == '4' ~ '3', 
                               dilution == '5' ~ '4', 
                               dilution == '6' ~ '5')) %>%
  mutate(replicate = case_when(replicate == '1:100' ~ '1', 
                               replicate == '1:10,000' ~ '2'))%>% 
  mutate(ideal_nM = case_when(benchmark == '1' ~ 0.1, 
                              benchmark == '2' ~ 0.04, 
                              benchmark == '3' ~ 0.02, 
                              benchmark == '4' ~ 0.01, 
                              benchmark == '5' ~ 0.005, 
                              benchmark == '6' ~ 0.0095)) %>% 
  mutate(ideal_nM=case_when(dilution == '7' ~ 0.0025, 
                            .default = ideal_nM))%>%
  mutate(log_pM = log(ideal_nM/dilution.factor*1000))

model_20250121 <- lm(Average.Ct~log_pM, benchmark_raw_1)
model_20250121[[1]][[2]]

ggplot(benchmark_raw_1)+
  geom_point(aes(x=log_pM, y=Average.Ct, color=benchmark))+
  geom_abline(slope=model_20250121[[1]][[2]], intercept=model_20250121[[1]][[1]])+
  theme_classic()
```

```{r}
raw <- read.xlsx("C:\\Users\\chand\\Box Sync\\Krasileva_Lab\\Research\\chandler\\Krasileva Lab\\E19\\Library qPCR\\20250527_2.xlsx", sheet='Concentration Analysis', startRow=1, fillMergedCells = TRUE)  %>%
  mutate(Ct=as.double(Ct))

benchmark_raw <- raw %>% 
  filter(str_detect(sample, '^benchmark')) %>% 
  subset(select=c(sample, Average.Ct, dilution.factor)) %>% 
  unique() %>% 
  separate(sample, into=c(NA, 'benchmark', NA, 'replicate'), sep=' ') %>%
  mutate(ideal_nM = case_when(benchmark == '1' ~ 0.1, 
                              benchmark == '2' ~ 0.04, 
                              benchmark == '3' ~ 0.02, 
                              benchmark == '4' ~ 0.01, 
                              benchmark == '5' ~ 0.005, 
                              benchmark == '6' ~ 0.0095)) %>% 
  mutate(log_pM = log(ideal_nM/dilution.factor*1000))



model_20250527 <- lm(Average.Ct~log_pM, benchmark_raw)
model_20250527[[1]][[2]]

ggplot(benchmark_raw)+
  geom_point(aes(x=log_pM, y=Average.Ct, color=benchmark))+
  geom_abline(slope=model_20250527[[1]][[2]], intercept=model_20250527[[1]][[1]])+
  theme_classic()
```
```{r}
raw <- read.xlsx("C:\\Users\\chand\\Box Sync\\Krasileva_Lab\\Research\\chandler\\Krasileva Lab\\E19\\Library qPCR\\20250527.xlsx", sheet='Concentration Analysis', startRow=1, fillMergedCells = TRUE)  %>%
  mutate(Ct=as.double(Ct))

benchmark_raw <- raw %>% 
  filter(str_detect(sample, '^benchmark')) %>% 
  subset(select=c(sample, Average.Ct, dilution.factor)) %>% 
  unique() %>% 
  separate(sample, into=c(NA, 'benchmark', NA, 'replicate'), sep=' ') %>%
  mutate(ideal_nM = case_when(benchmark == '1' ~ 0.1, 
                              benchmark == '2' ~ 0.04, 
                              benchmark == '3' ~ 0.02, 
                              benchmark == '4' ~ 0.01, 
                              benchmark == '5' ~ 0.005, 
                              benchmark == '6' ~ 0.0095)) %>% 
  mutate(log_pM = log(ideal_nM/dilution.factor*1000))



model_20250527 <- lm(Average.Ct~log_pM, benchmark_raw)
model_20250527[[1]][[2]]

ggplot(benchmark_raw)+
  geom_point(aes(x=log_pM, y=Average.Ct, color=benchmark))+
  geom_abline(slope=model_20250527[[1]][[2]], intercept=model_20250527[[1]][[1]])+
  theme_classic()
```

